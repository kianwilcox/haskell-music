%-*- mode: Latex; abbrev-mode: true; auto-fill-function: do-auto-fill -*-

%include lhs2TeX.fmt
%include myFormat.fmt

\out{
\begin{code}
-- This code was automatically generated by lhs2tex --code, from the file 
-- HSoM/SpectrumAnalysis.lhs.  (See HSoM/MakeCode.bat.)

\end{code}
}

\chapter{Spectrum Analysis}
\label{ch:spectrum-analysis}

\begin{code}
module Euterpea.Music.Signal.SpectrumAnalysis where

import Euterpea

import Data.Complex
import Data.List
-- import Math.FFT
\end{code}

There are many situations where it is desirable to take an existing
sound signal---in particular one that is recorded by a
microphone---and analyze it for its spectral content.  If one can do
this effectively, it is then possible (at least in theory) to recreate
the original sound, or to create novel variations of it.  The thepry
behind this approach is based on \emph{Fourier's Theorem}, which
states that any periodic signal can be decomposed into a weighted sum
of (a potentially infinite number of) sine waves.  In this chapter we
discuss the theory as well as the pragmatics for doing spectrum
analysis in Euterpea.

\section{Fourier's Theorem}
\label{sec:fouriers-theorem}

A \emph{periodic signal} is a signal that repeats itself infinitely
often.  Mathematically, a signal $x$ is periodic if there exists a
real number $T$ such that for all integers $n$:
\[ x(t) = x(t + nT) \]
%% \[ (\exists\ T\! \in\! \mathbb{R}) (\forall n\! \in\! \mathbb{Z}): x(t) = x(t + nT) \]
%% where $\mathbb{R}$ is the set of real numbers and $\mathbb{Z}$ is the
%% set of integers.  
$T$ is called the \emph{period}, which may be just a few microseconds,
a few seconds, or perhaps days---the only thing that matters is that
the signal repeats itself.  Usually we want to find the smallest value
of $T$ that satisfies the above property.  For example, a sine wave is
surely periodic; indeed, recall from Section \ref{sec:frequency} that:
\[ \sin (2\pi k + \theta) = \sin \theta \]
for any integer $k$. In this case, $T = 2\pi$, and it is the smallest
value that satisfies this property.

But in what sense is, for example, a single musical note periodic?
Indeed it is not, unless it is repeated infinitely often, which would
not be very interesting musically.  Yet something we would like to
know is the spectral content of that single note.  This is one of the
practical problems that we will address later in the chapter.

%% In the case of audio, since humans cannot hear sound lower than
%% about 20 Hz, we need only concern ourselves with periodic signals
%% whose repetition period is less than 50 milliseconds
%% (\nicefrac{1}{20} of a second).

Recall from Section \ref{sec:frequency} that a sine wave can be
represented by: $x(t) = A\sin(\omega t + \phi)$, where $A$ is the
amplitude, $\omega$ is the radian frequency, and $\phi$ is the phase
angle.  Joseph Fourier, a french mathematician and physicist, showed
the following result.  Any periodic signal $x(t)$ with period $T$ can
be represented as:
\begin{equation}\label{eq:fourier-series}
x(t) = C_0 + \sum_{n=1}^{\infty} C_n \cos(\omega_0 nt + \phi_n)
\end{equation}
This is called \emph{Fourier's Theorem}.  $\omega_0 =
\nicefrac{2\pi}{T}$ is called the \emph{fundamental frequency}.  Note
that the frequency of each cosine wave in the series is an integer
multiple of the fundamental frequency.  The above equation is also
called the \emph{Fourier series} or \emph{harmonic series} (related,
but not to be confused with, the mathematical definition of harmonic
series, which has the precise form $1 + \nicefrac{1}{2} +
\nicefrac{1}{3} + \nicefrac{1}{4} + \cdots$).

The trick, of course, is determining what the coefficients $C_0$,
$...$, $C_n$ and phase angles $\phi_1$, $...$, $\phi_n$ are.
Determining the above equation for a particular periodic signal is
called \emph{Fourier analysis}, and synthesizing a sound based on the
above equation is called \emph{Fourier synthesis}.  Theoretically, at
least, we should be able to use Fourier analysis to decompose a sound
of interest into its composite sine waves, and then regenerate it by
artificially generating those composite sine waves and adding them
together (i.e.\ additive synthesis, to be described in
Chapter~\ref{ch:additive}).  Of course, we also have to deal with the
fact that the representation may involve an \emph{infinite} number of
composite signals.

It turns out that many naturally occurring vibrations in
nature---including the resonances of most musical instruments---are
characterized as having a fundamental frequency (the perceived pitch)
and some combination of multiples of that frequency, which are often
called \emph{harmonics}, \emph{overtones} or \emph{partials}.

When studying Fourier analysis, it is more convenient, mathematically,
to use \emph{complex exponentials}.  We can relate working with
complex exponentials back to sines and cosines using \emph{Euler's
  Formula}:
\[\begin{array}{lcl}
e^{j\theta}   &=& cos(\theta) + j sin(\theta) \\[.05in]
cos(\theta) &=& \dfrac{1}{2} (e^{j\theta} + e^{-j\theta}) \\[.1in]
sin(\theta) &=& \dfrac{1}{2} (e^{j\theta} - e^{-j\theta})
\end{array}\]

For a periodic signal $x(t)$, %% which we will consider to be a
function of time, we will denote its \emph{Fourier transform} by
$\hat{x}(f)$, which is a function of frequency.  Each point in
$\hat{x}$ is a complex number that represents the magnitude and phase
of the frequency $f$'s presence in $x(t)$.  Using complex
exponentials, the formula for $\hat{x}(f)$ in terms of $x(t)$ is: \[
\hat{x}(f) = \int_{-\infty}^{\infty} x(t) e^{-j\omega t} dt \] where
$\omega = 2\pi f$, and $j$ is the same as the imaginary unit $i$ used
in mathematics.\footnote{Historically, engineers prefer to use the
symbol $j$ rather than $i$, because $i$ is generally used to represent
current in an electrical circuit.}  Intuitively, the Fourier transform
at a particular frequency $f$ is the integral of the product of the
original signal and a pure sinusiodal wave $e^{-j\omega t}$.  This
latter process is related to the \emph{convolution} of the two
signals, and intuitively will be non-zero only when the signal has
some content of that pure signal in it.

The above equation describes $\hat{x}$ in terms of $x$.  We can also
go the other way around---defining $x$ in terms of $\hat{x}$:
\[ x(t) = \int_{-\infty}^{\infty} \hat{x}(f) e^{j\hat{\omega} f} df \]
where $\hat{\omega} = 2\pi t$.  This is called the \emph{inverse}
Fourier transform.

%% -2 pi i x e  =>  -2 pi j t f  =>  -j w t
%%  2 pi i x e  =>   2 pi j t f  =>  -j what f

If we expand the definitions of $\omega$ and $\hat{\omega}$ we can see
  how similar these two equations are:
%% \[\begin{array}{lcl}
\begin{equation}\label{eq:ft}
\hat{x}(f) = \int_{-\infty}^{\infty} x(t)       e^{-j2\pi f t} dt
\end{equation}
\begin{equation}\label{eq:ift}
   x(t)    = \int_{-\infty}^{\infty} \hat{x}(f) e^{ j2\pi f t} df
\end{equation}
%% \end{array}\]
These two equations, for the Fourier transform and its inverse, are
remarkable in their simplicity and power.  They are also remarkable in
the following sense: \emph{no information is lost when converting from
  one to the other}.  In other words, a signal can be represented in
terms of its time-varying behavior or its spectral content---they are
equivalent!

A function that has the property that $f(x) = f(-x)$ is called an
\emph{even} function; if $f(x) = - f(-x)$ it is said to be \emph{odd}.
It turns out that \emph{any} function can be expressed as the sum of a
single even function and a single odd function.  This may help provide
some intuition about the equations for the Fourier transform, because
the complex exponential $e^{j2\pi f t}$ separates the waveform by
which it is being multiplied into its even and odd parts (recall
Euler's formula).  The real (cosine) part affects only the even part
of the input, and the imaginary (sine) part affects only the odd part
of the input.

Let's consider some examples, which are illustrated in
Figure~\ref{fig:fourier-transforms}:
\begin{itemize}
\item
Intuitively, the Fourier transform of a pure cosine wave should be an
impulse function---that is, the spectral content of a cosine wave
should be concentrated completely at the frequency of the cosine wave.
The only catch is that, when working in the complex domain, the
Fourier transform also yields the mirror image of the spectral
content, at a frequency that is the negation of the cosine wave's
frequency, as shown in Figure~\ref{fig:fourier-transforms}a.  In other
words, in this case, $\hat{x}(f) = \hat{x}(-f)$, i.e.\ $\hat{x}$ is
even.  So the spectral content is the \emph{real} part of the complex
number returned from the Fourier transform (recall Euler's formula).

\item
In the case of a pure sine wave, we should expect a similar result.
The only catch now is that the spectral content is contained in the
\emph{imaginary} part of the complex number returned from the Fourier
transform (recall Euler's formula), and the mirror image is negated.
That is, $\hat{x}(f) = - \hat{x}(-f)$, i.e.\ $\hat{x}$ is odd.  This
is illustrated in Figure~\ref{fig:fourier-transforms}b.

\item
Conversely, consider what the spectral content of an impulse function
should be.  Because an impulse function is infinitely ``sharp,'' it
would seem that its spectrum should contain energy at every point in
the frequency domain.  Indeed, the Fourier transform of an impulse
function centered at zero is a constant, as shown in
Figure~\ref{fig:fourier-transforms}c.

\item
Consider now the spectral content of a square wave.  It can be shown
that the Fourier series representation of a square wave is the sum of
the square wave's fundamental frequency plus its decreasing (in
magnitude) odd harmonics.  Specifically:
\begin{equation}\label{eq:square-wave-series}
sq(t) = \sum_{k=1}^{\infty} \frac{1}{k} \sin k\omega t,\quad {\rm for\ odd\ } k
\end{equation}
The spectral content of this signal in shown in
Figure~\ref{fig:fourier-transforms}d.
Figure~\ref{fig:square-wave-series} also shows partial reconstruction
of the square wave from a finite number of its composite signals.
\end{itemize}

It is worth noting that the diagrams in
Figure~\ref{fig:fourier-transforms} make no assumptions about time or
frequency.  Therefore, because the Fourier transform and its inverse
are true mathematical inverses, we can read the diagrams as time
domain / frequency domain pairs, or the other way around; i.e.\ as
frequency domain / time domain pairs.  For example, interpreting the
diagram on the left of Figure~\ref{fig:fourier-transforms}a in the
frequency domain, is to say that it is the Fourier transform of the
signal on the right (interpreted in the time domain).

\begin{figure}[hbtp]
\centering
\includegraphics[height=2.4in,angle=270]{pics/cosine1.eps}
\includegraphics[height=2.4in,angle=270]{pics/cosine2.eps}
\begin{center}
(a) Cosine wave
\end{center}
\includegraphics[height=2.4in,angle=270]{pics/sine1.eps} 
\includegraphics[height=2.4in,angle=270]{pics/sine2.eps} 
\begin{center}
(b) Sine wave
\end{center}
\includegraphics[height=2.4in,angle=270]{pics/pulse1.eps}
\includegraphics[height=2.4in,angle=270]{pics/pulse2.eps}
\begin{center}
(c) Impulse function
\end{center}
\includegraphics[height=2.4in,angle=270]{pics/square1.eps} 
\includegraphics[height=2.4in,angle=270]{pics/square2.eps} 
\begin{center}
(d) Square wave 
\end{center}
\caption{Examples of Fourier Transforms}
\label{fig:fourier-transforms}
\end{figure}

\begin{figure}[hbtp]
\centering
\includegraphics[height=2.4in,angle=270]{pics/19_2a.eps}
\begin{center}
(a) Sine wave
\end{center}
\includegraphics[height=2.4in,angle=270]{pics/19_2b.eps} 
\begin{center}
(b) Sine wave + third harmonic
\end{center}
\includegraphics[height=2.4in,angle=270]{pics/19_2c.eps} 
\begin{center}
(c) Since wave + third and fifth harmonics
\end{center}
\includegraphics[height=2.4in,angle=270]{pics/19_2d.eps} 
\begin{center}
(d) Sum of first eight terms of the Fourier series of a square wave
\end{center}
\caption{Generating a Square Wave from Odd Harmonics}
\label{fig:square-wave-series}
\end{figure}

\section{The Discrete Fourier Transform}
\label{sec:DFT}

Recall from Section \ref{sec:discrete} that we can move from the
continuous signal domain to the discrete domain by replacing the time
$t$ with the quantity $\nicefrac{n}{r}$, where $n$ is the integer
index into the sequence of discrete samples, and $r$ is the sampling
rate.  Let us assume that we have done this for $x$, and we will use
square brackets to denote the difference.  That is, $x[n]$ denotes the
$n^{\rm th}$ sample of the continuous signal $x(t)$, corresponding to
the value $x(\nicefrac{n}{r})$.

We would now like to compute the \emph{Discrete Fourier Transform}
(DFT) of our discrete signal.  But instead of being concerned about
the sampling rate (which can introduce aliasing, for example), our
concern turns to the \emph{number of samples} that we use in computing
the DFT---let's call this $N$.  Intuitively, the integrals used in our
equations for the Fourier transform and its inverse should become sums
over the range $0 ... N-1$.  This leads to a reformulation of our two
equations (\ref{eq:ft} and \ref{eq:ift}) as:
\begin{equation}\label{eq:dft}
\hat{x}[k] = \frac{1}{N}\sum_{n=0}^{N-1} 
               x[n] e^{-j\frac{2\pi k n}{N}},\ \ k = 0, 1, ..., N-1
\end{equation}
%% Analogously, the equation for the inverse DFT is:
\begin{equation}\label{eq:idft}
x[n] = \sum_{k=0}^{N-1} 
          \hat{x}[k] e^{j\frac{2\pi k n}{N}},\ \ n = 0, 1, ..., N-1
\end{equation}

Despite all of the mathematics up to this point, the reader may now
realize that the discrete Fourier transform as expressed above is
amenable to implementation---for example it should not be difficult to
write Haskell functions that realize each of the above equations.  But
before addressing implementation issues, let's discuss a bit more what
the results actually \emph{mean}.

\subsection{Interpreting the Frequency Spectrum}
\label{sec:freq-spectrum}

Just as $x[n]$ represents a sampled version of the continuous input
signal, $\hat{x}[k]$ represents a sampled version of the continous
frequency spectrum.  Care must be taken when interpreting either of
these results, keeping in mind the Nyquist-Shannon Sampling Theorem
(recall Section~\ref{sec:digital-audio}) and aliasing
(Section~\ref{sec:aliasing}).

Also recall that the result of a Fourier transform of a periodic
signal is a Fourier series (see Section~\ref{sec:fouriers-theorem}),
in which the signal being analyzed is expressed as multiples of a
fundamental frequency.  In equation \ref{eq:dft} above, that
fundamental frequency is the inverse of the duration of the $N$
samples, i.e.\ the inverse of $\nicefrac{N}{r}$, or $\nicefrac{r}{N}$.
For example, if the sampling rate is 44.1 kHz (the CD standard), then:
\begin{itemize}
%% \item If we take $N=44$ samples, then the fundamental frequency will
%%  be (about) $r/N = 1000$ Hz.
\item If we take $N=441$ samples, then the fundamental frequency will
  be $\nicefrac{r}{N} = 100$ Hz.
\item If we take $N=4410$ samples, then the fundamental frequency will
  be $\nicefrac{r}{N} = 10$ Hz.
\item If we take $N=44100$ samples, then the fundamental frequency will
  be $\nicefrac{r}{N} = 1$ Hz.
\end{itemize}
Thus, as would be expected, taking more samples yields a \emph{finer}
resolution of the frequency spectrum.  On the other hand, note that if
we increase the sampling rate and keep the number of samples fixed, we
get a \emph{courser} resolution of the spectrum---this also should be
expected, because if we increase the sampling rate we would expect to
have to look at more samples to get the same accuracy.

Analogous to the Nyquist-Shannon Sampling Theorem, the representable
points in the resulting frequency spectrum lie in the range
$\pm\nicefrac{r}{2}$, i.e.\ between plus and minus one-half of the
sampling rate.  For the above three cases, respectively, that means
the points are:
\begin{itemize}
%% \item -22 kHz, -21 kHz, ..., -1 kHz,   0, 1 kHz,   ..., 21 kHz, 22kHz
%% \item 
%% -22.05 kHz, -21.95 kHz, ..., -0.05 kHz, 0.05 kHz, ..., 21.95 kHz, 22.05 kHz
\item 
  -22.0 kHz, -21.9 kHz, ..., -0.1 kHz, 0, 0.1 kHz, ..., 21.9 kHz, 22.0 kHz
\item
  -22.05 kHz, -22.04 kHz,  ..., -10 Hz, 0, 10 Hz,   ..., 22.04 kHz, 22.05 kHz
\item 
  -22.05 kHz, -22.049 kHz, ..., -1 Hz, 0, 1 Hz,    ..., 22.049 kHz, 22.05 kHz
\end{itemize}
For practical purposes, the first of these is usually too course, the
third is too fine, and the middle one is useful for many applications.

Note that the first range of frequencies above does not quite cover
the range $\pm\nicefrac{r}{2}$.  But remember that this is a discrete
representation of the actual frequency spectrum, and the proper
interpretation would include the frequences $+\nicefrac{r}{2}$ and
$-\nicefrac{r}{2}$.

Also note that there are $N+1$ points in each of the above ranges, not
$N$.  Indeed, the more general question is, how do these points in the
frequency spectrum correspond to the indices $i = 0, 1, ..., N-1$ in
$\hat{x}[i]$?  If we denote each of these frequencies as $f$, the
answer is that:
\begin{equation}\label{eq:f1}
f = \frac{ir}{N},\ \ \ \ i = 0, 1, ..., N-1
\end{equation}
But note that this range of frequencies extends from $0$ to
$(N-1)(\nicefrac{r}{N})$, which exceeds the Nyquist-Shannon sampling
limit of $\nicefrac{r}{2}$.  The way out of this dilemma is to realize
that the DFT assumes that the input signal is periodic in time, and
therefore the DFT is periodic in frequency.  In other words, values of
$f$ for indices $i$ greater than $\nicefrac{N}{2}$ can be interpreted
as frequencies that are the \emph{negation} of the frequency given by
the formula above.  Assuming even $N$, we can revise formula
\ref{eq:f1} as follows:
\begin{equation}\label{eq:f2}
f = \left\{
      \begin{array}{ll}
        i\dfrac{r}{N},    & \quad i = 0, 1, ..., \dfrac{N}{2}    \\[0.1in]
        (i-N)\dfrac{r}{N} & \quad i = \dfrac{N}{2}, 
                                        \dfrac{N}{2}+1, ..., N-1 \\
      \end{array} \right.
\end{equation}
Note that when $i = \nicefrac{N}{2}$, both equations apply, yielding
$f = \nicefrac{r}{2}$ in the first case, and $f = -\nicefrac{r}{2}$ in
the second.  Indeed, the magnitude of the DFT for each of these
frequencies is the same (see discussion in the next section),
reflecting the periodicity of the DFT, and thus is simply a form of
redundancy.

%% \begin{itemize}
%% \item
%%   $\hat{x}[i],\ i = 0, 1, 2, ..., \frac{N}{2}$ correspond to the
%%   frequencies $0, \frac{r}{N}, \frac{2r}{N}, ..., \frac{r}{2}$.
%% \item
%%   $\hat{x}[i],\ i = \frac{N}{2}, \frac{N}{2}+1, \frac{N}{2}+2, ..., N-1$ 
%%   correspond to the frequencies 
%%   $-\frac{r}{2}, -\frac{r}{2}+\frac{r}{N}, -\frac{r}{2}+\frac{2r}{N}, 
%%   ..., -\frac{r}{N}$.
%% \end{itemize} 
%% ... This can be viewed s a kind of aliasing in the frequency domain.

The above discussion has assumed a periodic signal whose fundamental
frequency is presumably known, thus allowing us to parameterize the
DFT with the same fundamental frequency.  In practice this rarely
happens.  That is, the fundamental frequency of the DFT typically has
no integral relationship to the period of the periodic signal.  This
raises the question, what happens to the frequencies that ``fall in
the gaps'' between the frequencies discussed above?  The answer is
that the energy of that frequency component will be distributed
amongst neighboring points in a way that makes sense mathematically,
although the result may look a little funny compared to the ideal
result (where every frequency component is an integer multiple of the
fundamental).  The important thing to remember is that these are
digital representations of the exact spectra, just as a digitized
signal is representative of an exact signal.  Two digitized signals
can look very different (depending on sample rate, phase angle, and so
on), yet represent the same underlying signal---the same is true of a
digitized spectrum.

In practice, for reasons of computational efficiency, $N$ is usually
chosen to be a power of two.  We will return to this issue when we
discuss implementing the DFT.

[show on-line demo of FFT]

\subsection{Amplitude and Power of Spectrum}
\label{sec:amp-spectrum}

We discussed above how each sample in the result of a DFT relates to a
point in the frequency spectrum of the input signal.  But how do we
determine the amplitude and phase angle of each of those frequency
components?  In general each sample in the result of a DFT is a
complex number, thus having both a real and imaginary part, of the
form $a + jb$.  We can visualize this number as a point in the complex
Cartesian plane, where the abscissa (x-axis) represents the real part,
and the ordinate (y-axis) represents the imaginary part, as shown in
Figure~\ref{fig:complex-plane}.  It is easy to see that the line from
the origin to the point of interest is a vector $A$, whose length is
the \emph{amplitude} of the frequency component in the spectrum:
\begin{equation}\label{eq:amplitude}
A = \sqrt{a^2 + b^2}
\end{equation}
The angle $\theta$ is the \emph{phase}, and it is easily defined from
the figure as:
\begin{equation}\label{eq:phase}
\theta = tan^{-1} \frac{b}{a}
\end{equation}
(This amplitude / phase pair is often called the \emph{polar}
representation of a complex number.)

\begin{figure}[hbtp]
\centering
%% \includegraphics[height=4in,angle=270]{pics/sinewave.eps} 
[ figure showing the complex point (a,b) (say, in quadrant 2)
  along with its polar (magnitude/phase) representation ]
\caption{Complex Coordinates}
\label{fig:complex-plane}
\end{figure}

Recall from Section~\ref{sec:amplitude} that power is proportional to
the square of the amplitude.  Since taking a square root adds
computational expense, the square root is often omitted from
Equation~\ref{eq:amplitude}, thus yielding a \emph{power spectrum}
instead of an \emph{amplitude spectrum}.

One subtle aspect of the resulting DFT is how to interpret
\emph{negative} frequencies.  In the case of having an input whose
samples are all real numbers (i.e.\ there are no imaginary
components), which is true for audio applications, the negative
spectrum is a mirror image of the positive spectrum, and the
amplitude/power is distributed evenly between the two.

\subsection{A Haskell Implementation of the DFT}
\label{sec:haskell-dft}

From equation \ref{eq:dft}, which defines the DFT mathematically, we
can write a Haskell program that implements the DFT.  

The first thing we need to do is understand how complex numbers are
handled in Haskell.  They are captured in the |Complex| library, which
must be imported into any program that uses them.  The type |Complex
T| is the type of complex numbers whose underlying numeric type is
|T|.  We will use, for example, |Complex Double| for testing our DFT.
A complex number $a + jb$ is represented in Haskell as |a :+ b|, and
since |(:+)| is a constructor, such values can be pattern matched.

\syn{Complex numbers in Haskell are captured in the |Complex| library,
  in which complex numbers are defined as a polymorphic data type:
\begin{spec}
infix  6  :+
data (RealFloat a) => Complex a = !a :+ !a
\end{spec}
The ``|!|'' in front of the type variables declares that the
constructor |(:+)| is strict in its arguments.  For example, the
complex number $a + jb$ is represented by |a :+ b| in Haskell.  One
can pattern match on complex number values to extract the real and
imaginary parts, or use one of the predefined selectors defined in the
|Complex| library:
\begin{spec}
realPart, imagPart  :: RealFloat a => Complex a -> a
\end{spec}
The |Complex| library also defines the following functions:
\begin{spec}
conjugate           :: RealFloat a => Complex a -> Complex a
mkPolar             :: RealFloat a => a -> a -> Complex a
cis                 :: RealFloat a => a -> Complex a
polar               :: RealFloat a => Complex a -> (a,a)
magnitude, phase    :: RealFloat a => Complex a -> a
\end{spec}
The library also declares instances of |Complex| for the type classes
|Num|, |Fractional|, and |Floating|.
}

Although not as efficient as arrays, for simplicity we choose to use
lists to represent the vectors that are the input and output of the
DFT.  Thus if |xs| is the list that represents the signal $x$, then
|xs!!n| is the |n+1|$^{th}$ sample of that signal, and is equivalent
to $x[n]$.  Furthermore, using list comprehensions, we can make the
Haskell code look very much like the mathematical definition captured
in Equation \ref{eq:dft}.  Finally, we adopt the convention that the
length of the input signal is the number of samples that we will use
for the DFT.

Probably the trickiest part of writing a Haskell program for the DFT
is dealing with the types!  In particular, if you look closely at
Equation \ref{eq:dft} you will see that $N$ is used in three different
ways---as an integer (for indexing), as a real number (in the exponent
of $e$), and as a complex number (in the expression
$\nicefrac{1}{N}$).

Here is a Haskell program that implements the DFT:
\begin{code}
dft :: RealFloat a => [Complex a] -> [Complex a]
dft xs = 
  let  lenI = length xs
       lenR = fromIntegral lenI
       lenC = lenR :+ 0
  in [  let i = -2 * pi * fromIntegral k / lenR
        in (1/lenC) * sum [  (xs!!n) * exp (0 :+ i * fromIntegral n)
                             | n <- [0,1..lenI-1] ]
        | k <- [0,1..lenI-1] ]
\end{code}
Note that |lenI|, |lenR|, and |lenC| are the integer, real, and
complex versions, respectively, of $N$.  Otherwise the code is fairly
straightforward---note in particular how list comprehensions are used
to implement the ranges of $n$ and $k$ in Equation \ref{eq:dft}.

To test our program, let's first create a couple of waveforms.  For
example, recall that Equation \ref{eq:square-wave-series} defines the
Fourier series for a square wave.  We can implement the first, first
two, and first three terms of this series, corresponding respectively
to Figures~\ref{fig:square-wave-series}a,
\ref{fig:square-wave-series}b, and \ref{fig:square-wave-series}c, by
the following Haskell code:
\begin{code}
mkTerm :: Int -> Double -> [Complex Double]
mkTerm num n = let f = 2 * pi / fromIntegral num
               in map (:+ 0) [  sin (n * f * fromIntegral i) / n
                                | i <- [0,1..num-1] ]

mkxa, mkxb, mkxc :: Int-> [Complex Double]
mkxa num = mkTerm num 1
mkxb num = zipWith (+) (mkxa num) (mkTerm num 3)
mkxc num = zipWith (+) (mkxb num) (mkTerm num 5)
\end{code}
|mkTerm num n| is the n${^th}$ term in the series, using $num$ samples.

Using the helper function |printComplexL| defined in
Figure~\ref{fig:pp-code}, which ``pretty prints'' a list of complex
numbers, we can look at the result of our DFT in a more readable
form.\footnote{``Pretty-printing'' real numbers is a subtle task.  The
  code in Figure~\ref{fig:pp-code} rounds the numnber to 10 decimal
  places of accuracy, and inserts spaces before and after to line up
  the decimal points and give a consistent string length.  The
  fractional part is not padded with zeros, since that would give a
  false impression of its accuracy.  (It is not necessary to
  understand this code in order to understand the concepts in this
  chapter.)}

\begin{figure}
\begin{code}
printComplexL :: [Complex Double] -> IO ()
printComplexL xs  =
  let  f (i,rl:+im) = 
            do  putStr (spaces (3 - length (show i))  )
                putStr (show i       ++ ":  ("        )
                putStr (niceNum rl  ++ ", "           )
                putStr (niceNum im  ++ ")\n"          )
  in mapM_ f (zip [0..length xs - 1] xs)

niceNum :: Double -> String
niceNum d =
  let  d' = fromIntegral (round (1e10 * d)) / 1e10
       (dec, fra)  = break (== '.') (show d')
       (fra',exp)  = break (== 'e') fra
  in  spaces (3  - length dec) ++ dec ++ take 11 fra'
      ++ exp ++ spaces (12 - length fra' - length exp)

spaces :: Int -> String
spaces  n = take n (repeat ' ')
\end{code}
\caption{Helper Code for Pretty-Printing DFT Results}
\label{fig:pp-code}
\end{figure}

For example, suppose we want to take the DFT of a 16-sample
representation of the first three terms of the square wave series.
Typing the following at the GHCi prompt:
\begin{spec}
printComplexL (dft (mkxc 16))
\end{spec}
will yield the result of the DFT, pretty-printing each number as a
pair, along with its index:
\begin{verbatim}
  0:  (  0.0          ,   0.0          )
  1:  (  0.0          ,  -0.5          )
  2:  (  0.0          ,   0.0          )
  3:  (  0.0          ,  -0.1666666667 )
  4:  (  0.0          ,   0.0          )
  5:  (  0.0          ,  -0.1          )
  6:  (  0.0          ,   0.0          )
  7:  (  0.0          ,   0.0          )
  8:  (  0.0          ,   0.0          )
  9:  (  0.0          ,   0.0          )
 10:  (  0.0          ,   0.0          )
 11:  (  0.0          ,   0.1          )
 12:  (  0.0          ,   0.0          )
 13:  (  0.0          ,   0.1666666667 )
 14:  (  0.0          ,   0.0          )
 15:  (  0.0          ,   0.5          )
\end{verbatim}

\out{
 0:  (  0.00000,   0.00000 )
 1:  (  0.00000,  -0.50000 )
 2:  (  0.00000,   0.00000 )
 3:  (  0.00000,  -0.16667 )
 4:  (  0.00000,   0.00000 )
 5:  (  0.00000,  -0.10000 )
 6:  (  0.00000,   0.00000 )
 7:  (  0.00000,   0.00000 )
 8:  (  0.00000,   0.00000 )
 9:  (  0.00000,   0.00000 )
10:  (  0.00000,   0.00000 )
11:  (  0.00000,   0.10000 )
12:  (  0.00000,   0.00000 )
13:  (  0.00000,   0.16667 )
14:  (  0.00000,   0.00000 )
15:  (  0.00000,   0.50000 )
}

Let's study this result more closely.  For sake of argument, assume a
sample rate of 1.6 KHz.  Then by construction using |mkxc|, our
square-wave input's fundamental frequency is 100 Hz.  Similarly,
recall that the resolution of the DFT is $r/N$, which is also 100 Hz.

Now compare the overall result to Figure
\ref{fig:fourier-transforms}b.  Recalling also Equation \ref{eq:f2},
we note that the above DFT results are non-zero precisely at 100, 300,
500, -500, -300, and -100 Hz.  This is just what we would expect.
Furthermore, the amplitudes are one-half of the corresponding
harmonically decreasing weights dictated by Equation
\ref{eq:square-wave-series}, namely the values 1, $\nicefrac{1}{6}$,
and $\nicefrac{1}{10}$ (recall the discussion in Section
\ref{sec:amp-spectrum}).

Let's do another example.  We can create an impulse function as
follows:
\begin{code}
mkPulse :: Int -> [Complex Double]
mkPulse n = 100 : take (n-1) (repeat 0)
\end{code}
and print its DFT with the command:
\begin{spec}
printComplexL (dft (mkPulse 16))
\end{spec}
whose effect is:
\begin{verbatim}
 0:  (  6.25         ,   0.0          )
 1:  (  6.25         ,   0.0          )
 2:  (  6.25         ,   0.0          )
 3:  (  6.25         ,   0.0          )
 4:  (  6.25         ,   0.0          )
 5:  (  6.25         ,   0.0          )
 6:  (  6.25         ,   0.0          )
 7:  (  6.25         ,   0.0          )
 8:  (  6.25         ,   0.0          )
 9:  (  6.25         ,   0.0          )
10:  (  6.25         ,   0.0          )
11:  (  6.25         ,   0.0          )
12:  (  6.25         ,   0.0          )
13:  (  6.25         ,   0.0          )
14:  (  6.25         ,   0.0          )
15:  (  6.25         ,   0.0          )

\end{verbatim}
Compare this to Figure \ref{fig:fourier-transforms}c, and note how the
original magnitude of the impulse (100) is distributed evenly among
the 16 points in the DFT ($100/16 = 6.25$).

\out{
 0:  (  6.25000,   0.00000 )
 1:  (  6.25000,   0.00000 )
 2:  (  6.25000,   0.00000 )
 3:  (  6.25000,   0.00000 )
 4:  (  6.25000,   0.00000 )
 5:  (  6.25000,   0.00000 )
 6:  (  6.25000,   0.00000 )
 7:  (  6.25000,   0.00000 )
 8:  (  6.25000,   0.00000 )
 9:  (  6.25000,   0.00000 )
10:  (  6.25000,   0.00000 )
11:  (  6.25000,   0.00000 )
12:  (  6.25000,   0.00000 )
13:  (  6.25000,   0.00000 )
14:  (  6.25000,   0.00000 )
15:  (  6.25000,   0.00000 )
}

So far we have considered only input signals whose frequency
components are integral multiples of the DFT's resolution.  This
rarely happens in practice, however, because music is simply too
complex, and noisy.  As mentioned in \ref{sec:freq-spectrum}, the
energy of the signals that ``fall in the gaps'' is distributed among
neighboring points, although not in as simple a way as you might
think.  To get some perspective on this, let's do one other example.
We define a function to generate a signal whose frequeny is $\pi$
times the fundamental frequency:
%% We will modify the function |mkTerm| so that it creates a signal
%% 42\% higher than it used to be:
\begin{code}
x1 num = let f = pi * 2 * pi / fromIntegral num
         in map (:+ 0) [  sin (f * fromIntegral i)
                          | i <- [0,1..num-1] ]
\end{code}
$\pi$ is an irrational number, but any number that ``falls in the
gaps'' between indices would do.  We can see the result by typing the
command:
\begin{spec}
printComplexL (dft x1)
\end{spec}
which yields:
\begin{verbatim}
  0:  ( -7.9582433e-3 ,   0.0          )
  1:  ( -5.8639942e-3 ,  -1.56630897e-2)
  2:  (  4.7412105e-3 ,  -4.56112124e-2)
  3:  (  0.1860052232 ,  -0.4318552865 )
  4:  ( -5.72962095e-2,   7.33993364e-2)
  5:  ( -3.95845728e-2,   3.14378088e-2)
  6:  ( -3.47994673e-2,   1.65400768e-2)
  7:  ( -3.29813518e-2,   7.4048103e-3 )
  8:  ( -3.24834325e-2,   0.0          )
  9:  ( -3.29813518e-2,  -7.4048103e-3 )
 10:  ( -3.47994673e-2,  -1.65400768e-2)
 11:  ( -3.95845728e-2,  -3.14378088e-2)
 12:  ( -5.72962095e-2,  -7.33993364e-2)
 13:  (  0.1860052232 ,   0.4318552865 )
 14:  (  4.7412105e-3 ,   4.56112124e-2)
 15:  ( -5.8639942e-3 ,   1.56630897e-2)
\end{verbatim}
This is much more complicated than the previous examples!  Not only do
the points in the spectrum seem to have varying amounts of energy,
they also have both non-zero real and non-zero imaginary components,
meaning that the magnitude and phase vary at each point.  We can
define a function that converts a list of complex numbers into a list
of their polar representations as follows:
\begin{code}
mkPolars :: [Complex Double] -> [Complex Double]
mkPolars = map ((\(m,p)-> m:+p) . polar)
\end{code}
which we can then use to reprint our result:
\begin{spec}
printComplexL (mkPolars (dft x1))
\end{spec}
\begin{verbatim}
  0:  (  7.9582433e-3 ,   3.1415926536 )
  1:  (  1.67247961e-2,  -1.9290259418 )
  2:  (  4.58569709e-2,  -1.4672199604 )
  3:  (  0.470209455  ,  -1.1640975898 )
  4:  (  9.31145435e-2,   2.2336013741 )
  5:  (  5.05497204e-2,   2.4704023271 )
  6:  (  3.85302097e-2,   2.6979021519 )
  7:  (  3.38023784e-2,   2.9207398294 )
  8:  (  3.24834325e-2,  -3.1415926536 )
  9:  (  3.38023784e-2,  -2.9207398294 )
 10:  (  3.85302097e-2,  -2.6979021519 )
 11:  (  5.05497204e-2,  -2.4704023271 )
 12:  (  9.31145435e-2,  -2.2336013741 )
 13:  (  0.470209455  ,   1.1640975898 )
 14:  (  4.58569709e-2,   1.4672199604 )
 15:  (  1.67247961e-2,   1.9290259418 )
\end{verbatim}
If we focus on the magnitude (the first column), we can see that there
is a peak near index 3 (corresponding roughly to the frequency $\pi$),
with small amounts of energy elsewhere.

\vspace{.1in}\hrule

\begin{exercise}{\em 
Write a Haskell function |idft| that implements the \emph{inverse} DFT
as captured in Equation~\ref{eq:ift}.  Test your code by applying
|idft| to one of the signals used earlier in this section.  In other
words, show empirically that, up to round-off errors, |idft (dft xs)
== xs|. }
\end{exercise}

\begin{exercise}{\em 
Use |dft| to analyze some of the signals generated using signal
functions defined in Chapter~\ref{ch:sigfuns}. }
\end{exercise}

\todo{To do the above exercise we need to provide a function that
  extracts |N| samples from a sigfun, and somehow keeps it in the
  sigfun world.  Perhaps something like:

\begin{spec}
sample :: Rate -> Int -> Signal c a (Event (Table a))
\end{spec}
such that |sample r n| is a sigfun that generates an event every |1/r|
seconds, each event being a table containing |n| samples of the
input.  These tables may or may not overlap, depending on the
relationship between |r|, |n|, and the sampling rate. }

\begin{exercise}{\em
Define a function |mkSqWave :: Int -> Int -> [Complex Double]| such
that |mxSqWave num n| is the sum of the first $n$ terms of the Fourier
series of a square wave, having $num$ samples in the result. }
\end{exercise}

\begin{exercise}{\em
Prove mathematically that $x$ and $\hat{x}$ are inverses.  Also prove,
using equational reasoning, that |dft| and |idft| are inverses.  (For
the latter you may assume that Haskell numeric types obey the standard
axioms of real arithmetic.) }
\end{exercise}

\vspace{.1in}\hrule

\vspace{.1in}

\section{The Fast Fourier Transform}
\label{sec:fft}

Our effort in the last section was toward writing a DFT program in
Haskell that was as faithful to Equation ...

We can think of $x[n]$ and $\hat{x}[k]$ as vectors.  Thus, for
example, each element of $\hat{x}$ is the sum of $N$ multiplications
of a vector by a complex exponential (which can be represented as a
pair, the real and imaginary parts).  And this overall process must be
repeated for each value of $k$, also $N$ times.  Therefore the overall
complexity of the implied algorithm is O($N^2$).

For even moderate values of $N$, this can be computationally
impractical.  Fortunately, there exists a much faster algorithm called
the \emph{Fast Fourier Transform}, or FFT, that reduces the complexity
to O($N\log N$).  This difference is quite significant for larger
values of $N$.\footnote{The basic FFT algorithm was invented by James
  Cooley and John Tukey in 1965.}

%% \footnote{James Cooley and John Tukey are
%%   usually credited with inventing the FFT in 1965, although it was
%%   later discovered that Carl Friedrich Gauss proposed the same
%%   algorithm around 1805.}

We will not go into the details of the FFT algorithm, but instead
will use a Haskell library ...


\section{Further Pragmatics}

... Of course, when moving into the discrete domain, the problems we
mentioned earlier come into play, and result, for example, in
``windowing'' effects.

... To understand all this a little better, let's begin with some simple
examples of what happens when we add sine waves together.

\out{ Old Code

%% printComplexL :: [Complex Double] -> IO ()
%% printComplexL xs  =
%%   let maxLr = maximum (map (length . fst . break (== '.') . show . realPart) xs)
%%       maxRr = maximum (map (length . snd . break (== '.') . show . realPart) xs)
%%       maxLi = maximum (map (length . fst . break (== '.') . show . imagPart) xs)
%%       maxRi = maximum (map (length . snd . break (== '.') . show . imagPart) xs)
%%       nl = length (show (length xs))
%%       f (i,rl:+im) = do  putStr ( mkLenP nl (show i)  ++ ":  ("   )
%%                          putStr ( pad maxLr maxRr rl    ++ ", "   )
%%                          putStr ( pad maxLi maxRi im    ++ ")\n"  )
%%   in mapM_ f (zip [0..length xs - 1] xs)

%% pad :: Int -> Int -> Double -> String
%% pad maxL maxR x =
%%   let  (dec,fra)  = break (== '.') (show x)
%%   in take (maxL - length dec) (repeat ' ') ++ dec ++
%%      fra ++ take (maxR - length fra) (repeat ' ')

%% mkLenP :: Int -> String -> String
%% mkLenP n xs =  
%%   let diff = n - length xs
%%   in  if diff < 0 then error "number is too big"
%%       else take diff (repeat ' ') ++ xs -- pad the prefix

%% mkNiceNum :: Int -> Double -> String
%% mkNiceNum n d =
%%   let  (dec, fra)  = break (== '.') (show d)
%%   in mkLenP n dec ++ "." ++ mkLenS m (tail fra)

%% mkLenP :: Int -> Double -> String
%% mkLenP n x =  
%%   let diff = n - length xs
%%   in  if diff < 0 then error "number is too big"
%%       else take diff (repeat ' ') ++ xs -- pad the prefix

%% mkLenS :: Int -> String -> String
%% mkLenS m xs = 
%%   let diff = m - length xs
%%   in  if diff < 0 then take m xs
%%       else xs ++ take diff (repeat '0') -- pad the suffix

%% printComplexL :: Int -> Int -> [Complex Double] -> IO ()
%% printComplexL n m xs  =
%%   -- n is the number of chars to the left of the decimal point
%%   -- m is the number of chars to the right
%%   let nl = length (show (length xs))
%%       f (i,rl:+im) = do  putStr ( mkLenP nl (show i)  ++ ":  (" )
%%                          putStr ( mkNiceNum n m rl    ++ ", "   )
%%                          putStr ( mkNiceNum n m im    ++ " )\n" )
%%   in mapM_ f (zip [0..length xs - 1] xs)

%% mkNiceNum :: Int -> Int -> Double -> String
%% mkNiceNum n m d =
%%   let  s           = 10 ^ m
%%        dRnd        = fromIntegral (round (s*d)) / s  :: Double
%%        (dec, fra)  = break (== '.') (show dRnd)
%%   in mkLenP n dec ++ "." ++ mkLenS m (tail fra)

%% mkLenP :: Int -> String -> String
%% mkLenP n xs =  
%%   let diff = n - length xs
%%   in  if diff < 0 then error "number is too big"
%%       else take diff (repeat ' ') ++ xs -- pad the prefix

%% mkLenS :: Int -> String -> String
%% mkLenS m xs = 
%%   let diff = m - length xs
%%   in  if diff < 0 then take m xs
%%       else xs ++ take diff (repeat '0') -- pad the suffix

%% dft' :: [Complex Double] -> [Complex Double]
%% dft' xs = 
%%   let lenI = length xs
%%       lenR = fromIntegral lenI
%%       lenC = lenR :+ 0
%%   in [  (1/lenC) * sum [  (xs!!n) * 
%%                              let  y :: Double
%%                                   y = -2 * pi *  fromIntegral k * 
%%                                                  fromIntegral n / lenR
%%                              in cos y :+ sin y
%%                           | n <- [0,1..lenI-1] ]
%%         | k <- [0,1..lenI-1] ]

%% dft'' :: [Complex Double] -> [Complex Double]
%% dft'' xs = 
%%   let lenI = length xs
%%       lenR = fromIntegral lenI
%%       lenC = lenR :+ 0
%%   in [  (1/lenC) * sum [  (xs!!n) * 
%%                              let  y :: Double
%%                                   y = (2 * pi *  fromIntegral k * 
%%                                                  fromIntegral n) / lenR
%%                              in cos y :+ (- sin y)
%%                           | n <- [0,1..lenI-1] ]
%%         | k <- [0,1..lenI-1] ]

%% mkNiceNum' :: Int -> Int -> Double -> String
%% mkNiceNum' n m d =
%%   let s           = 10 ^ n
%%       dRnd        = fromIntegral (round (s*d)) / s  :: Double
%%       (dec, fra)  = break (== '.') (show dRnd)
%%       (fra',exp)  = break (== 'e') fra
%%   in  if null exp
%%       then mkLenP n dec ++ "." ++ mkLenS m (tail fra)
%%       else mkLenP n dec ++ "." ++ mkLenS (m - length exp) (tail fra) ++ exp
}

